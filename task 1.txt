Python mein is link sy data fetch kren then download url sy only csv files parse kren Or csv files ki data ki hr row ki dictionary bna k print krwani hai.
import requests
import csv
import io
import os
url = "https://api.github.com/repos/CSSEGISandData/COVID-19/contents/csse_covid_19_data/csse_covid_19_daily_reports"
response = requests.get(url)

# Send an HTTP GET request to the URL with stream=True
response = requests.get(url, stream=True)

# Check if the request was successful (HTTP status code 200)
if response.status_code == 200:
    # Parse the JSON response
    data = response.json()

    # Create a directory to store the downloaded files if it doesn't exist
    download_directory = "covid_data"
    if not os.path.exists(download_directory):
        os.makedirs(download_directory)

    # Loop through the files in the response and download each one
    for file_info in data:
        file_name = file_info["name"]
        file_url = file_info["download_url"]
        file_path = os.path.join(download_directory, file_name)

        # Send an HTTP GET request to the file URL with stream=True
        file_response = requests.get(file_url, stream=True)

        # Check if the request was successful
        if file_response.status_code == 200:
            # Save the content to a file in chunks
            with open(file_path, "wb") as file:
                for chunk in file_response.iter_content(chunk_size=8192):
                    file.write(chunk)
            print(f"Downloaded {file_name}")
        else:
            print(f"Failed to download {file_name}")
else:
    print(f"Failed to fetch data from {url}")
# Check if the directory exists
if os.path.exists(download_directory):
    # List all files in the directory
    downloaded_files = os.listdir(download_directory)

    # Iterate through the downloaded files
    for file_name in downloaded_files:
        file_path = os.path.join(download_directory, file_name)

        # Check if the file is a CSV file (you may want to add more checks)
        if file_name.endswith(".csv"):
            print(f"Parsing {file_name}")

            # Create a list to store dictionaries for each row
            data_list = []

            # Open the CSV file for reading
            with open(file_path, "r") as csv_file:
                # Create a CSV reader
                csv_reader = csv.DictReader(csv_file)

                # Iterate through each row in the CSV file
                for row in csv_reader:
                    # Append the row as a dictionary to the list
                    data_list.append(row)

            # Now, you have a list of dictionaries for the rows in the CSV file
            # You can work with this data as needed
            # For example, you can print the first few rows:
            for i, row_dict in enumerate(data_list[:5]):  # Print the first 5 rows as an example
                print(f"Row {i + 1}: {row_dict}")
        else:
            print(f"Skipping non-CSV file: {file_name}")
else:
    print("Download directory not found.")
